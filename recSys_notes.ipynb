{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bulding a recommender system\n",
    "\n",
    "\n",
    "* The first step is to generate recommendations candidates: items we think might be interesting\n",
    "to the user based on their past behavior.\n",
    "* Candidate ranking: many candidates will appear more than once and need to be combined\n",
    "in some way, maybe boosting their score in the process. The main goal is to find a optimal\n",
    "ranking of candidate at this stage. This ranking stage might also have access to more information\n",
    "about the recommendation candidates that it can use such as average review scores for popular items.\n",
    "* Some filtering will be required before presenting the final sorted list. This stage is\n",
    "where we might eliminate recommendations for items the user has already rated. We also apply a\n",
    "stop list here to remove items thar are potentially offensive to the user.\n",
    "\n",
    "The output of the filtering stage is then handed off to you display layer where a pretty\n",
    "widget of product recommendations is presented to the user. Generally speaking, the candidate\n",
    "generation, ranking and filtering will live inside some distributed recommendation web service\n",
    "that your web front-end talks to in the process of rendering a page for a specific user. This is\n",
    "what we call item-based collaborative filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuracy metrics\n",
    "\n",
    "Let's say we have $n$ ratings in our test set. For each rating we can call the rating out system\n",
    "predicts, $y$, and the rating the user actually gave, $x$.\n",
    "\n",
    "Mean Square Error = $\\frac{ \\sum_{i=1}^{n} | y_i - x_i |}{n} $\n",
    "\n",
    "Another one very popular is RMSE. It penalizes you more when your rating prediction is\n",
    "way off, and penalizes less when you were reasonably close.\n",
    "\n",
    "\n",
    "Root mean square error = $\\sqrt( \\frac{ \\sum_{i=1}^{n} ( y_i - x_i )^2}{n})$\n",
    "\n",
    "Typically in recommender systems literature, the RMSE metric is broadly use.\n",
    "\n",
    "### Evaluating top-n recommenders\n",
    "* hit rate: Ypu generate top end recommendations for all of the users in your test set.\n",
    "If one of the recommendations in a user is top end recommendations is something they actually rated,\n",
    "you consider that a hit.\n",
    "* $$ \\frac{hits}{users} $$\n",
    "* leave-one-out cross validation: Compute top end recommendations for each user in our training data,\n",
    "and intentionally remove one of those items from that users in training data. We then test our\n",
    "recommender system's ability to recommend that item that was left out in the top end results\n",
    "it created for that user in the testing phase.\n",
    "* Average reciprocal hit rate (ARHR): this metrics is just like hit rate, but it accounts for\n",
    "where in the top end list your hits appear. So you end up getting more credit successfully recommending\n",
    "an item in the top slot, that in the bottom slot.\n",
    "* $\\frac{\\sum_{i=1}^{n} \\frac{1}{rank_i}}{users}$\n",
    "\n",
    "### Coverage, diversity, and novelty\n",
    "\n",
    "* coverage: the percentage of possible recommendations that your system is able to provide. It can also\n",
    "be important to watch because it gives a sense og how quickly new items in your catalog will start\n",
    "to appear in recommendations\n",
    "* diversity: It is a measure of how broad a variety of items in your recommender system is putting\n",
    "in front of people.\n",
    "* novelty: It is a measure of how popular them items are that you are recommending.\n",
    "\n",
    "### Churn and responsiveness\n",
    "* Churn: It can measure how sensitive your recommender system is to new user behavior. If a user rates\n",
    "a new movie, does that substantially change their recommendations? If so, then you churn score will be high.\n",
    "* responsiveness: how quickly does new user behavior influence your recommendations?\n",
    "\n",
    "### A/B Tests\n",
    "* You can put recommendations from different algorithms in front of different sets of users\n",
    "and measure if they actually buy, watch, or otherwise indicate interest in the recommendations you have presented.\n",
    "* By always testing changes to your recommender system using controlled online experiments, you\n",
    "can see if they actually cause people to discover and purchase more new things than they would\n",
    "have otherwise. At the end of the day, the results of online AB test are the only evaluation that matters.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}